{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Лабораторная работа 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**При обучении нейронных сетей чаще всего используются следующие функции потерь:**\n",
        "- **Mean Squared Error - MSE.**\n",
        "- **Mean Absolute Error - MAE.**\n",
        "- **Mean Absolute Percentage Error - MAPE.**\n",
        "- **Binary Crossentropy.**\n",
        "- **Categorical Crossentropy.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./images/lab2-mse.jpg\" alt=\"MSE\" width=\"400px\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXa79By9QsYK"
      },
      "source": [
        "1. Расчет среднеквадратической ошибки\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g_jQcxmQdCd",
        "outputId": "4d593062-1216-4a94-adf0-28bfa6292318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.30250000000000005\n"
          ]
        }
      ],
      "source": [
        "weight = 0.5\n",
        "input = 0.5\n",
        "goal_prediction = 0.8\n",
        "\n",
        "pred = input * weight\n",
        "error = (pred - goal_prediction) ** 2\n",
        "print(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO1yJfCvkeh4"
      },
      "source": [
        "2. Попробуем обучить сеть, изменяя вес в разные стороны и рассчитывая значение ошибки для каждого изменения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5saxge5FQytb",
        "outputId": "7d98726a-6e58-4220-9185-d1fec9394dc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5\n",
            "Error:0.30250000000000005 Prediction:0.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n",
            "2.5\n",
            "Error:0.20249999999999996 Prediction:1.25\n",
            "1.5\n",
            "Error:0.0025000000000000044 Prediction:0.75\n"
          ]
        }
      ],
      "source": [
        "weight = 0.5\n",
        "input = 0.5\n",
        "goal_prediction = 0.8\n",
        "\n",
        "step_amount = 1\n",
        "\n",
        "for iteration in range(100):\n",
        "    print(weight)\n",
        "    prediction = input * weight\n",
        "    error = (prediction - goal_prediction) ** 2\n",
        "\n",
        "    print(\"Error:\" + str(error) + \" Prediction:\" + str(prediction))\n",
        "\n",
        "    up_prediction = input * (weight + step_amount)  # попробовать увеличить\n",
        "    up_error = (goal_prediction - up_prediction) ** 2\n",
        "\n",
        "    down_prediction = input * (weight - step_amount)  # попробовать уменьшить\n",
        "    down_error = (goal_prediction - down_prediction) ** 2\n",
        "\n",
        "    if down_error < up_error:\n",
        "        weight = (\n",
        "            weight - step_amount\n",
        "        )  # если уменьшение дало лучший результат, уменьшить\n",
        "\n",
        "    if down_error > up_error:\n",
        "        weight = (\n",
        "            weight + step_amount\n",
        "        )  # если увеличение дало лучший результат, увеличить"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Число итераций** - С увеличением числа итераций приходим к более низкой величине ошибки. С уменьшением числа итераций ошибка становится недостаточно минимизированной.\n",
        "<br/>\n",
        "\n",
        "**Размер шага** - При слишком большом шаге (например, 0.1, 1, 2, 10, 100, ...) не удается достичь оптимального состояния. Мы все время \"перешагиваем\" через истинное значение веса. При слишком маленьком шаге можем просто не дойти до желаемого оптимального значения.\n",
        "<br/>\n",
        "\n",
        "**Поэтому необходимо уделять должное внимание подбору оптимальных параметров нейронный сети (кол-во эпох, коэффициент обучения, ...)!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Рассмотрим идею градиентного спуска**\n",
        "\n",
        "<img src=\"./images/lab2-gradient_descent.jpg\" alt=\"image\" width=\"500\" height=\"400\">\n",
        "<img src=\"./images/lab2-grad_descent_steps.png\" width=\"500\" height=\"400\" style=\"margin-left: 20px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPnFsGB2yLLX"
      },
      "source": [
        "3. Реализуйте градиентный спуск: определите направление и величину изменения веса, используя производную функции потерь для текущего веса . Выполните 20 итераций градиентного спуска .\n",
        " weight = weight - derivative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0ck5Tuf1k1RM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weight=0.5000\n",
            "pred=0.2500 error=0.3025 grad=-0.5500\n",
            "weight=1.0500\n",
            "pred=0.5250 error=0.0756 grad=-0.2750\n",
            "weight=1.3250\n",
            "pred=0.6625 error=0.0189 grad=-0.1375\n",
            "weight=1.4625\n",
            "pred=0.7313 error=0.0047 grad=-0.0687\n",
            "weight=1.5312\n",
            "pred=0.7656 error=0.0012 grad=-0.0344\n",
            "weight=1.5656\n",
            "pred=0.7828 error=0.0003 grad=-0.0172\n",
            "weight=1.5828\n",
            "pred=0.7914 error=0.0001 grad=-0.0086\n",
            "weight=1.5914\n",
            "pred=0.7957 error=0.0000 grad=-0.0043\n",
            "weight=1.5957\n",
            "pred=0.7979 error=0.0000 grad=-0.0021\n",
            "weight=1.5979\n",
            "pred=0.7989 error=0.0000 grad=-0.0011\n",
            "weight=1.5989\n",
            "pred=0.7995 error=0.0000 grad=-0.0005\n",
            "weight=1.5995\n",
            "pred=0.7997 error=0.0000 grad=-0.0003\n",
            "weight=1.5997\n",
            "pred=0.7999 error=0.0000 grad=-0.0001\n",
            "weight=1.5999\n",
            "pred=0.7999 error=0.0000 grad=-0.0001\n",
            "weight=1.5999\n",
            "pred=0.8000 error=0.0000 grad=-0.0000\n",
            "weight=1.6000\n",
            "pred=0.8000 error=0.0000 grad=-0.0000\n",
            "weight=1.6000\n",
            "pred=0.8000 error=0.0000 grad=-0.0000\n",
            "weight=1.6000\n",
            "pred=0.8000 error=0.0000 grad=-0.0000\n",
            "weight=1.6000\n",
            "pred=0.8000 error=0.0000 grad=-0.0000\n",
            "weight=1.6000\n",
            "pred=0.8000 error=0.0000 grad=-0.0000\n"
          ]
        }
      ],
      "source": [
        "weight = 0.5\n",
        "goal_prediction = 0.8\n",
        "input = 0.5\n",
        "\n",
        "for iteration in range(20):\n",
        "    print(f\"{weight=:.4f}\")\n",
        "    pred = input * weight\n",
        "    error = (pred - goal_prediction) ** 2\n",
        "    grad = 2 * (pred - goal_prediction) * input\n",
        "    print(f\"{pred=:.4f} {error=:.4f} {grad=:.4f}\")\n",
        "    weight = weight - grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Получили оптимальное значение веса! : )**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь попробуем все сломать.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dUxqxPL1yjrq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weight=0.5000\n",
            "pred=1.0000 error=0.0400 grad=0.8000\n",
            "weight=-0.3000\n",
            "pred=-0.6000 error=1.9600 grad=-5.6000\n",
            "weight=5.3000\n",
            "pred=10.6000 error=96.0400 grad=39.2000\n",
            "weight=-33.9000\n",
            "pred=-67.8000 error=4705.9600 grad=-274.4000\n",
            "weight=240.5000\n",
            "pred=481.0000 error=230592.0400 grad=1920.8000\n",
            "weight=-1680.3000\n",
            "pred=-3360.6000 error=11299009.9600 grad=-13445.6000\n",
            "weight=11765.3000\n",
            "pred=23530.6000 error=553651488.0400 grad=94119.2000\n",
            "weight=-82353.9000\n",
            "pred=-164707.8000 error=27128922913.9600 grad=-658834.4000\n",
            "weight=576480.5000\n",
            "pred=1152961.0000 error=1329317222784.0388 grad=4611840.8000\n",
            "weight=-4035360.3000\n",
            "pred=-8070720.6000 error=65136543916417.8906 grad=-32282885.6000\n",
            "weight=28247525.3000\n",
            "pred=56495050.6000 error=3191690651904477.0000 grad=225980199.2000\n",
            "weight=-197732673.9000\n",
            "pred=-395465347.8000 error=156392841943319392.0000 grad=-1581861394.4000\n",
            "weight=1384128720.5000\n",
            "pred=2768257441.0000 error=7663249255222649856.0000 grad=11073029760.8000\n",
            "weight=-9688901040.3000\n",
            "pred=-19377802080.6000 error=375499213505909817344.0000 grad=-77511208325.6000\n",
            "weight=67822307285.3000\n",
            "pred=135644614570.5999 error=18399461461789578887168.0000 grad=542578458279.1997\n",
            "weight=-474756150993.8997\n",
            "pred=-949512301987.7994 error=901573611627689308848128.0000 grad=-3798049207954.3979\n",
            "weight=3323293056960.4980\n",
            "pred=6646586113920.9961 error=44177106969756774925598720.0000 grad=26586344455680.7852\n",
            "weight=-23263051398720.2891\n",
            "pred=-46526102797440.5781 error=2164678241518082040073814016.0000 grad=-186104411189765.5000\n",
            "weight=162841359791045.2188\n",
            "pred=325682719582090.4375 error=106069233834386021338006421504.0000 grad=1302730878328358.5000\n",
            "weight=-1139889518537313.2500\n",
            "pred=-2279779037074626.5000 error=5197392457884915573327895986176.0000 grad=-9119116148298510.0000\n"
          ]
        }
      ],
      "source": [
        "weight = 0.5\n",
        "goal_prediction = 0.8\n",
        "input = 2.0\n",
        "\n",
        "for iteration in range(20):\n",
        "    print(f\"{weight=:.4f}\")\n",
        "    pred = input * weight\n",
        "    error = (pred - goal_prediction) ** 2\n",
        "    grad = 2 * (pred - goal_prediction) * input\n",
        "    print(f\"{pred=:.4f} {error=:.4f} {grad=:.4f}\")\n",
        "    weight = weight - grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Столкнулись со \"взрывающимся градиентом\".. Из-за слишком большого входного значения получили слишком большой градиент. Как следствие, после корректировки вес стал слишком большим, что привело к еще большему градиенту и т.д.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDJf1TwqFApX"
      },
      "source": [
        "4. Реализуйте алгоритм градиентного спуска, добавив параметр скорости обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5wY0e-9zFACV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weight=0.5000\n",
            "pred=0.2500 error=0.3025 grad=-0.5500\n",
            "weight=0.7750\n",
            "pred=0.3875 error=0.1702 grad=-0.4125\n",
            "weight=0.9813\n",
            "pred=0.4906 error=0.0957 grad=-0.3094\n",
            "weight=1.1359\n",
            "pred=0.5680 error=0.0538 grad=-0.2320\n",
            "weight=1.2520\n",
            "pred=0.6260 error=0.0303 grad=-0.1740\n",
            "weight=1.3390\n",
            "pred=0.6695 error=0.0170 grad=-0.1305\n",
            "weight=1.4042\n",
            "pred=0.7021 error=0.0096 grad=-0.0979\n",
            "weight=1.4532\n",
            "pred=0.7266 error=0.0054 grad=-0.0734\n",
            "weight=1.4899\n",
            "pred=0.7449 error=0.0030 grad=-0.0551\n",
            "weight=1.5174\n",
            "pred=0.7587 error=0.0017 grad=-0.0413\n",
            "weight=1.5381\n",
            "pred=0.7690 error=0.0010 grad=-0.0310\n",
            "weight=1.5535\n",
            "pred=0.7768 error=0.0005 grad=-0.0232\n",
            "weight=1.5652\n",
            "pred=0.7826 error=0.0003 grad=-0.0174\n",
            "weight=1.5739\n",
            "pred=0.7869 error=0.0002 grad=-0.0131\n",
            "weight=1.5804\n",
            "pred=0.7902 error=0.0001 grad=-0.0098\n",
            "weight=1.5853\n",
            "pred=0.7927 error=0.0001 grad=-0.0073\n",
            "weight=1.5890\n",
            "pred=0.7945 error=0.0000 grad=-0.0055\n",
            "weight=1.5917\n",
            "pred=0.7959 error=0.0000 grad=-0.0041\n",
            "weight=1.5938\n",
            "pred=0.7969 error=0.0000 grad=-0.0031\n",
            "weight=1.5953\n",
            "pred=0.7977 error=0.0000 grad=-0.0023\n"
          ]
        }
      ],
      "source": [
        "weight = 0.5\n",
        "goal_prediction = 0.8\n",
        "input = 0.5\n",
        "learning_rate = 0.5\n",
        "\n",
        "for iteration in range(20):\n",
        "    print(f\"{weight=:.4f}\")\n",
        "    pred = input * weight\n",
        "    error = (pred - goal_prediction) ** 2\n",
        "    grad = 2 * (pred - goal_prediction) * input\n",
        "    print(f\"{pred=:.4f} {error=:.4f} {grad=:.4f}\")\n",
        "    weight = weight - learning_rate * grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Для 20-ти итераций и инпута, равного 0.5, хорошим значением коэффициента обучения будет 0,5. Так мы успеем прийти к нулевой ошибке за 20 итераций и сможем избежать дестабилизирующих значений градиента.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQV-wxoJFoy7"
      },
      "source": [
        "Что происходит при input=2?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wZdnsn-BFwaG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weight=0.5000\n",
            "pred=1.0000 error=0.0400 grad=0.8000\n",
            "weight=0.4600\n",
            "pred=0.9200 error=0.0144 grad=0.4800\n",
            "weight=0.4360\n",
            "pred=0.8720 error=0.0052 grad=0.2880\n",
            "weight=0.4216\n",
            "pred=0.8432 error=0.0019 grad=0.1728\n",
            "weight=0.4130\n",
            "pred=0.8259 error=0.0007 grad=0.1037\n",
            "weight=0.4078\n",
            "pred=0.8156 error=0.0002 grad=0.0622\n",
            "weight=0.4047\n",
            "pred=0.8093 error=0.0001 grad=0.0373\n",
            "weight=0.4028\n",
            "pred=0.8056 error=0.0000 grad=0.0224\n",
            "weight=0.4017\n",
            "pred=0.8034 error=0.0000 grad=0.0134\n",
            "weight=0.4010\n",
            "pred=0.8020 error=0.0000 grad=0.0081\n",
            "weight=0.4006\n",
            "pred=0.8012 error=0.0000 grad=0.0048\n",
            "weight=0.4004\n",
            "pred=0.8007 error=0.0000 grad=0.0029\n",
            "weight=0.4002\n",
            "pred=0.8004 error=0.0000 grad=0.0017\n",
            "weight=0.4001\n",
            "pred=0.8003 error=0.0000 grad=0.0010\n",
            "weight=0.4001\n",
            "pred=0.8002 error=0.0000 grad=0.0006\n",
            "weight=0.4000\n",
            "pred=0.8001 error=0.0000 grad=0.0004\n",
            "weight=0.4000\n",
            "pred=0.8001 error=0.0000 grad=0.0002\n",
            "weight=0.4000\n",
            "pred=0.8000 error=0.0000 grad=0.0001\n",
            "weight=0.4000\n",
            "pred=0.8000 error=0.0000 grad=0.0001\n",
            "weight=0.4000\n",
            "pred=0.8000 error=0.0000 grad=0.0000\n"
          ]
        }
      ],
      "source": [
        "weight = 0.5\n",
        "goal_prediction = 0.8\n",
        "input = 2.0\n",
        "learning_rate = 0.05\n",
        "\n",
        "for iteration in range(20):\n",
        "    print(f\"{weight=:.4f}\")\n",
        "    pred = input * weight\n",
        "    error = (pred - goal_prediction) ** 2\n",
        "    grad = 2 * (pred - goal_prediction) * input\n",
        "    print(f\"{pred=:.4f} {error=:.4f} {grad=:.4f}\")\n",
        "    weight = weight - learning_rate * grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Для input, равного 2.0, лучше взять коэффициент обучения 0.05. В таком случае алгоритм сойдется к минимум функции ошибки.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14ajZ3OZgt5w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3iFv6m5iYRX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
